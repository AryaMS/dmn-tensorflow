{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "bAbi data_loader\n",
    "Original code : https://github.com/YerevaNN/Dynamic-memory-networks-in-Theano/blob/master/utils.py\n",
    "\"\"\"\n",
    "\n",
    "import os as os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    \n",
    "    def __init__(self, task_id, task_test_id, w2v_dim=100, input_mask_mode=\"sentence\"):\n",
    "        self.base_path = os.path.join(\"data/\")\n",
    "        \n",
    "        self.task_id = str(task_id)\n",
    "        self.task_test_id = str(task_test_id)\n",
    "        self.w2v_dim = w2v_dim\n",
    "        self.input_mask_mode = input_mask_mode\n",
    "        \n",
    "    def make_train_ans_test_set(self):\n",
    "        train_raw, test_raw = self.get_babi_raw(self.task_id, self.task_test_id)\n",
    "        \n",
    "        self.word2vec = self.load_glove(self.w2v_dim)\n",
    "        self.vocab = {}\n",
    "        self.ivocab = {}\n",
    "        \n",
    "        train_input, train_question, train_answer, train_input_mask = self.process_input(train_raw)\n",
    "        test_input, test_question, test_answer, test_input_mask = self.process_input(test_raw)\n",
    "        \n",
    "        return {\n",
    "            \"train\": (train_input, train_input_mask, train_question, train_answer),\n",
    "            \"test\": (test_input, test_input_mask, test_question, test_answer)\n",
    "        }\n",
    "    \n",
    "\n",
    "    def init_babi(self, fname):\n",
    "        print(\"==> Loading test from %s\" % fname)\n",
    "        tasks = []\n",
    "        task = None\n",
    "        for i, line in enumerate(open(fname)):\n",
    "            id = int(line[0:line.find(' ')])\n",
    "            if id == 1:\n",
    "                task = {\"C\": \"\", \"Q\": \"\", \"A\": \"\"}\n",
    "\n",
    "            line = line.strip()\n",
    "            line = line.replace('.', ' . ')\n",
    "            line = line[line.find(' ')+1:]\n",
    "            if line.find('?') == -1:\n",
    "                task[\"C\"] += line\n",
    "            else:\n",
    "                idx = line.find('?')\n",
    "                tmp = line[idx+1:].split('\\t')\n",
    "                task[\"Q\"] = line[:idx]\n",
    "                task[\"A\"] = tmp[1].strip()\n",
    "                tasks.append(task.copy())\n",
    "\n",
    "        return tasks\n",
    "\n",
    "\n",
    "    def get_babi_raw(self, id, test_id):\n",
    "        babi_map = {\n",
    "            \"1\": \"qa1_single-supporting-fact\",\n",
    "            \"2\": \"qa2_two-supporting-facts\",\n",
    "            \"3\": \"qa3_three-supporting-facts\",\n",
    "            \"4\": \"qa4_two-arg-relations\",\n",
    "            \"5\": \"qa5_three-arg-relations\",\n",
    "            \"6\": \"qa6_yes-no-questions\",\n",
    "            \"7\": \"qa7_counting\",\n",
    "            \"8\": \"qa8_lists-sets\",\n",
    "            \"9\": \"qa9_simple-negation\",\n",
    "            \"10\": \"qa10_indefinite-knowledge\",\n",
    "            \"11\": \"qa11_basic-coreference\",\n",
    "            \"12\": \"qa12_conjunction\",\n",
    "            \"13\": \"qa13_compound-coreference\",\n",
    "            \"14\": \"qa14_time-reasoning\",\n",
    "            \"15\": \"qa15_basic-deduction\",\n",
    "            \"16\": \"qa16_basic-induction\",\n",
    "            \"17\": \"qa17_positional-reasoning\",\n",
    "            \"18\": \"qa18_size-reasoning\",\n",
    "            \"19\": \"qa19_path-finding\",\n",
    "            \"20\": \"qa20_agents-motivations\",\n",
    "            \"MCTest\": \"MCTest\",\n",
    "            \"19changed\": \"19changed\",\n",
    "            \"joint\": \"all_shuffled\",\n",
    "            \"sh1\": \"../shuffled/qa1_single-supporting-fact\",\n",
    "            \"sh2\": \"../shuffled/qa2_two-supporting-facts\",\n",
    "            \"sh3\": \"../shuffled/qa3_three-supporting-facts\",\n",
    "            \"sh4\": \"../shuffled/qa4_two-arg-relations\",\n",
    "            \"sh5\": \"../shuffled/qa5_three-arg-relations\",\n",
    "            \"sh6\": \"../shuffled/qa6_yes-no-questions\",\n",
    "            \"sh7\": \"../shuffled/qa7_counting\",\n",
    "            \"sh8\": \"../shuffled/qa8_lists-sets\",\n",
    "            \"sh9\": \"../shuffled/qa9_simple-negation\",\n",
    "            \"sh10\": \"../shuffled/qa10_indefinite-knowledge\",\n",
    "            \"sh11\": \"../shuffled/qa11_basic-coreference\",\n",
    "            \"sh12\": \"../shuffled/qa12_conjunction\",\n",
    "            \"sh13\": \"../shuffled/qa13_compound-coreference\",\n",
    "            \"sh14\": \"../shuffled/qa14_time-reasoning\",\n",
    "            \"sh15\": \"../shuffled/qa15_basic-deduction\",\n",
    "            \"sh16\": \"../shuffled/qa16_basic-induction\",\n",
    "            \"sh17\": \"../shuffled/qa17_positional-reasoning\",\n",
    "            \"sh18\": \"../shuffled/qa18_size-reasoning\",\n",
    "            \"sh19\": \"../shuffled/qa19_path-finding\",\n",
    "            \"sh20\": \"../shuffled/qa20_agents-motivations\",\n",
    "        }\n",
    "        if (test_id == \"\"):\n",
    "            test_id = id\n",
    "        babi_name = babi_map[id]\n",
    "        babi_test_name = babi_map[test_id]\n",
    "        babi_train_raw = self.init_babi(os.path.join(self.base_path, 'en-10k/%s_train.txt' % babi_name))\n",
    "        babi_test_raw = self.init_babi(os.path.join(self.base_path, 'en-10k/%s_test.txt' % babi_test_name))\n",
    "        return babi_train_raw, babi_test_raw\n",
    "\n",
    "\n",
    "    def load_glove(self, dim):\n",
    "        word2vec = {}\n",
    "\n",
    "        print(\"==> loading glove\")\n",
    "        with open(os.path.join(self.base_path, \"glove/glove.6B.\" + str(dim) + \"d.txt\")) as f:\n",
    "            for line in tqdm(f):\n",
    "                l = line.split()\n",
    "                word2vec[l[0]] = l[1:]\n",
    "\n",
    "        print(\"==> glove is loaded\")\n",
    "\n",
    "        return word2vec\n",
    "\n",
    "\n",
    "    def create_vector(self, word, silent=False):\n",
    "        # if the word is missing from Glove, create some fake vector and store in glove!\n",
    "        vector = np.random.uniform(0.0,1.0,(self.w2v_dim,))\n",
    "        self.word2vec[word] = vector\n",
    "        if (not silent):\n",
    "            print(\"data_loader.py::create_vector => %s is missing\" % word)\n",
    "        return vector\n",
    "\n",
    "\n",
    "    def process_word(self, word, to_return=\"word2vec\", silent=False):\n",
    "        if not word in self.word2vec:\n",
    "            self.create_vector(word, self.word2vec, self.w2v_dim, silent)\n",
    "        if not word in self.vocab:\n",
    "            next_index = len(self.vocab)\n",
    "            self.vocab[word] = next_index\n",
    "            self.ivocab[next_index] = word\n",
    "\n",
    "        if to_return == \"word2vec\":\n",
    "            return self.word2vec[word]\n",
    "        elif to_return == \"index\":\n",
    "            return self.vocab[word]\n",
    "        else:\n",
    "            raise ValueError(\"return type is 'word2vec' or 'index'\")\n",
    "\n",
    "\n",
    "    def get_norm(self, x):\n",
    "        x = np.array(x)\n",
    "        return np.sum(x * x)\n",
    "\n",
    "    def process_input(self, data_raw):\n",
    "        print(\"==> processing raw to vector\")\n",
    "        \n",
    "        questions = []\n",
    "        inputs = []\n",
    "        answers = []\n",
    "        input_masks = []\n",
    "        for x in tqdm(data_raw):\n",
    "            inp = x[\"C\"].lower().split(' ') \n",
    "            inp = [w for w in inp if len(w) > 0]\n",
    "            q = x[\"Q\"].lower().split(' ')\n",
    "            q = [w for w in q if len(w) > 0]\n",
    "\n",
    "            inp_vector = [self.process_word(word=w, to_return=\"word2vec\") for w in inp]\n",
    "            q_vector = [self.process_word(word=w, to_return=\"word2vec\") for w in q]\n",
    "\n",
    "\n",
    "            inputs.append(np.vstack(inp_vector).astype(float))\n",
    "            questions.append(np.vstack(q_vector).astype(float))\n",
    "            answers.append(self.process_word(word = x[\"A\"], to_return = \"index\"))\n",
    "            \n",
    "            # NOTE: here we assume the answer is one word! \n",
    "            if self.input_mask_mode == 'word':\n",
    "                input_masks.append(np.array([index for index, w in enumerate(inp)], dtype=np.int32)) \n",
    "            elif self.input_mask_mode == 'sentence': \n",
    "                input_masks.append(np.array([index for index, w in enumerate(inp) if w == '.'], dtype=np.int32)) \n",
    "            else:\n",
    "                raise ValueError(\"input_mask_mode is only available (word, sentence)\")\n",
    "\n",
    "        print(\"==> processing complete\")\n",
    "        return inputs, questions, answers, input_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11993it [00:00, 119921.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading test from data/en-10k/qa1_single-supporting-fact_train.txt\n",
      "==> Loading test from data/en-10k/qa1_single-supporting-fact_test.txt\n",
      "==> loading glove\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:05, 74030.01it/s] \n",
      "  2%|‚ñè         | 214/10000 [00:00<00:09, 1051.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> glove is loaded\n",
      "==> processing raw to vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:09<00:00, 1088.53it/s]\n",
      " 10%|‚ñà         | 104/1000 [00:00<00:00, 1034.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> processing complete\n",
      "==> processing raw to vector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 1048.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> processing complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(task_id=\"1\", task_test_id=\"1\", w2v_dim=50)\n",
    "data = data_loader.make_train_ans_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_input, train_input_mask, train_question, train_answer = data[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 50)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 11], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answer[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (NLP)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
